{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2SRi2RUYH_aD",
    "outputId": "3b7bc29b-a973-403d-8199-d920bd41b4ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘models’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir models\n",
    "import requests\n",
    "\n",
    "# files = ['regression.py','sindy_helper.py','dynamicalsystems.py','fullSINDyAutoencoder.py']\n",
    "# for name in files:\n",
    "#     with requests.get('https://raw.githubusercontent.com/audrey163/Autoencoder/main/'+name, stream=True) as r:\n",
    "#         r.raise_for_status()\n",
    "#         with open(name, 'wb') as f:\n",
    "#             for chunk in r.iter_content(chunk_size=8192): \n",
    "#                 f.write(chunk)\n",
    "import numpy as np\n",
    "import pprint as pp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "from scipy.stats import special_ortho_group\n",
    "from scipy.integrate import solve_ivp\n",
    "from regression import PolynomialLibrary, TrigLibrary\n",
    "import sindy_helper\n",
    "from dynamicalsystems import SimplePendulum\n",
    "from fullSINDyAutoencoder import FullSINDyAutoencoder\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device('cuda:0')\n",
    "#    print(\"GPU\")\n",
    "#else:\n",
    "#   print(\"CPU\")\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 412
    },
    "id": "GP9ddJHLXxpU",
    "outputId": "b96897dc-34d1-4ed4-fce5-e7c9e6bf33d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = SimplePendulum(g=9.8,l=2,mu=0.5,theta0=np.pi/2)\n",
    "total_samples = len(dataset)\n",
    "\n",
    "params = {\n",
    "    'architecture' : { \n",
    "        'input_dimension' : 10,\n",
    "        'latent_dimension' : 2 ,\n",
    "        'SIND-y' : {}\n",
    "    },\n",
    "    'optimization' : { \n",
    "        'learn_rate' : 1e-2,\n",
    "        'loss_reg' : {\n",
    "            'X' : 1,\n",
    "            'SINDy' : 1,\n",
    "            'dX' : 1, #dX is regularization is 0 because dX_pred = None\n",
    "            'Xi1' : 5,\n",
    "            'Xi2' : 5\n",
    "        }\n",
    "    },\n",
    "    'training' : {\n",
    "        'epochs' : 500,\n",
    "        'batch_size' : 500,\n",
    "        'save_freq' : 5,\n",
    "        'load_weghts_from' : ':latest' # 'random.init', ':latest', None, 'models/FILENAME'\n",
    "    },\n",
    "    'inputs' : {\n",
    "        'total_samples' : total_samples,\n",
    "    },\n",
    "    'outputs' : {\n",
    "        'loss' : True,\n",
    "        'sindy_show' : False,\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "dataset.to(device)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=params['training']['batch_size'], shuffle=True, num_workers=2)\n",
    "dataiter = iter(dataloader)\n",
    "\n",
    "def load_model(state_dict_PATH=None):\n",
    "    model = FullSINDyAutoencoder(params)\n",
    "    if state_dict_PATH is not None:\n",
    "        if state_dict_PATH == ':latest':\n",
    "            from os import listdir\n",
    "            from os.path import isfile, join\n",
    "            onlyfiles = [f for f in listdir('models/') if isfile(join('models/', f))]\n",
    "            onlyfiles.sort(reverse=True)\n",
    "            state_dict_PATH = 'models/' + onlyfiles[0]\n",
    "        model.load_state_dict(torch.load(state_dict_PATH))\n",
    "        print(\"Using Model: \" + state_dict_PATH)\n",
    "    return model\n",
    "\n",
    "#model = load_model(state_dict_PATH =':latest')\n",
    "model = load_model()\n",
    "model.to(device)\n",
    "#\n",
    "x = torch.tensor([1,2,3])\n",
    "x.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mB-O0rEJHhNr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "ML8RLkU5ZSRP",
    "outputId": "4631e1db-9a64-40f0-b61c-bf0288bbfac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "\tLoss: {'X': 83.5987548828125, 'dZ': 11.383085250854492, 'dX': 170.66781616210938, 'Xi1': 1.18890380859375, 'Xi2': 1.5188647508621216}\n",
      "Epoch 1\n",
      "\tLoss: {'X': 74.96044158935547, 'dZ': 35.47883987426758, 'dX': 174.59469604492188, 'Xi1': 0.3954358398914337, 'Xi2': 0.49556881189346313}\n",
      "Epoch 2\n"
     ]
    }
   ],
   "source": [
    "model.train(dataset,dataloader,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E2Uw1xL0vSuQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Autoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
